# -*- coding: utf-8 -*-
"""Modelo_Clasificación.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a8XbhIg08WY8RKnhktnHY17W5QlGMtXz
"""

from google.colab import drive
drive.mount('/content/drive')

"""***LIBRERÍAS***"""

# Importar las librerías necesarias
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import plot_tree
from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, recall_score, f1_score, precision_score

"""***BASE DE DATOS***"""

# Subir bases de datos
df_clas = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Modelo_cluster_variable_impacto.csv')
df_clas.info()

# Preparar los datos:  Seleccionar columnas para train y target
# Establecer columnas para el entrenamiento (training)
input_cols = df_clas[['SalesPerCustomer', 'CompetitionDistance', 'MonthsSinceCompetition']]
# Establecer columna Target (Dependiente)
target_col = df_clas['Cluster']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modelo Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)
rf_predictions = rf_model.predict(X_test)

# Modelo Árbol de Decisión
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)
dt_predictions = dt_model.predict(X_test)

# Evaluación de Random Forest
print("Random Forest")
print("Precisión:", accuracy_score(y_test, rf_predictions))
print("Matriz de Confusión:\n", confusion_matrix(y_test, rf_predictions))
print("Reporte de Clasificación:\n", classification_report(y_test, rf_predictions))

# Evaluación de Árbol de Decisión
print("\nÁrbol de Decisión")
print("Precisión:", accuracy_score(y_test, dt_predictions))
print("Matriz de Confusión:\n", confusion_matrix(y_test, dt_predictions))
print("Reporte de Clasificación:\n", classification_report(y_test, dt_predictions))

# ---- Ajuste de Hiperparámetros ----

# Grid Search para Random Forest
rf_param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, n_jobs=-1, verbose=2)
rf_grid_search.fit(X_train, y_train)
best_rf_model = rf_grid_search.best_estimator_

# Grid Search para Árbol de Decisión
dt_param_grid = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'criterion': ['gini', 'entropy']
}

dt_grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_param_grid, cv=5, n_jobs=-1, verbose=2)
dt_grid_search.fit(X_train, y_train)
best_dt_model = dt_grid_search.best_estimator_

# ---- Evaluación de Modelos Optimizados ----

# Predicciones con el modelo optimizado de Random Forest
rf_predictions = best_rf_model.predict(X_test)

# Predicciones con el modelo optimizado de Árbol de Decisión
dt_predictions = best_dt_model.predict(X_test)

# Evaluación de Random Forest
print("Random Forest Optimizado")
print("Precisión:", accuracy_score(y_test, rf_predictions))
print("Matriz de Confusión:\n", confusion_matrix(y_test, rf_predictions))
print("Reporte de Clasificación:\n", classification_report(y_test, rf_predictions))

# Evaluación de Árbol de Decisión
print("\nÁrbol de Decisión Optimizado")
print("Precisión:", accuracy_score(y_test, dt_predictions))
print("Matriz de Confusión:\n", confusion_matrix(y_test, dt_predictions))
print("Reporte de Clasificación:\n", classification_report(y_test, dt_predictions))

# ---- Análisis de Importancia de Variables ----
rf_importances = best_rf_model.feature_importances_
print("\nImportancia de Variables (Random Forest):")
for feature, importance in zip(X.columns, rf_importances):
    print(f"{feature}: {importance:.4f}")

# Permutation Importance (Método alternativo para medir la importancia)
perm_importance = permutation_importance(best_rf_model, X_test, y_test)
print("\nPermutation Importance:")
for i, feature in enumerate(X.columns):
    print(f"{feature}: {perm_importance.importances_mean[i]:.4f}")

"""**Importancia de Variables en Random Forest: Los resultados del modelo muestran la importancia de cada variable. Por ejemplo, si CompetitionDistance tiene una alta importancia, significa que la distancia a la competencia es un factor clave para clasificar a las tiendas en los clusters.**

**Permutation Importance: Este método evalúa cuánto cambia la precisión del modelo si se altera una variable en particular. Si la precisión disminuye significativamente al modificar una variable, esa variable es crucial para el modelo.**

**CompetitionDistance: Esta variable suele tener un gran impacto. Las tiendas más cercanas a la competencia podrían estar en clusters de menor rendimiento (Bajo) debido a la mayor presión competitiva. Por otro lado, las tiendas más alejadas pueden clasificarse en clusters de mejor rendimiento (Medio o Alto) debido a menos competencia directa.**

**MonthsSinceCompetition: Esta variable refleja cómo el tiempo transcurrido desde que la competencia entró al mercado afecta el rendimiento. Tiendas que han estado expuestas a la competencia durante más tiempo pueden haberse adaptado mejor, mientras que las nuevas podrían estar aún en proceso de ajuste, afectando su clasificación.**
"""

# ---- Gráfico de Importancia de Variables (Random Forest) ----
plt.figure(figsize=(10, 6))
feature_importances = best_rf_model.feature_importances_
sns.barplot(x=feature_importances, y=X.columns)
plt.title('Importancia de las Variables - Random Forest')
plt.xlabel('Importancia')
plt.ylabel('Variables')
plt.show()

# ---- Matriz de Confusión ----
def plot_confusion_matrix(cm, title='Matriz de Confusión', labels=['Bajo', 'Medio', 'Alto']):
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.title(title)
    plt.xlabel('Predicción')
    plt.ylabel('Actual')
    plt.show()

# Matriz de confusión para Random Forest
rf_cm = confusion_matrix(y_test, rf_predictions)
plot_confusion_matrix(rf_cm, title='Matriz de Confusión - Random Forest')

# Matriz de confusión para Árbol de Decisión
dt_cm = confusion_matrix(y_test, dt_predictions)
plot_confusion_matrix(dt_cm, title='Matriz de Confusión - Árbol de Decisión')

# ---- Gráfico del Árbol de Decisión ----
# Mostrar el árbol del modelo optimizado (si no es demasiado grande)
plt.figure(figsize=(20, 10))
plot_tree(best_dt_model, feature_names=X.columns, class_names=['Bajo', 'Medio', 'Alto'], filled=True, fontsize=10)
plt.title('Árbol de Decisión')
plt.show()

"""**Para desarrollar estrategias efectivas de retención de clientes basadas en el análisis de los modelos de clasificación y la influencia de las variables clave, es importante centrar las recomendaciones en cómo las tiendas pueden mejorar su desempeño en un entorno competitivo. Aquí te presento algunas recomendaciones basadas en los insights obtenidos:**

Enfocar Estrategias en Tiendas Cercanas a la Competencia (CompetitionDistance):
Recomendación:
Estrategias de Descuentos y Promociones: Las tiendas cercanas a competidores podrían beneficiarse de campañas agresivas de descuentos o promociones exclusivas para fidelizar a los clientes.
Programas de Lealtad: Implementa programas de puntos o recompensas para incentivar compras recurrentes. Estos programas deben ser atractivos y fáciles de entender para los clientes, con beneficios claros por sus compras continuas.
Impacto:
Mantener precios competitivos y ofrecer valor adicional ayudará a diferenciarse en un mercado saturado, incentivando a los clientes a elegir tu tienda sobre la competencia cercana.**
"""

# Crear un DataFrame con las métricas de ambos modelos para comparación
metrics = {
    'Modelo': ['Random Forest', 'Árbol de Decisión'],
    'Accuracy': [accuracy_score(y_test, rf_predictions), accuracy_score(y_test, dt_predictions)],
    'Recall': [recall_score(y_test, rf_predictions, average='weighted'), recall_score(y_test, dt_predictions, average='weighted')],
    'Precision': [precision_score(y_test, rf_predictions, average='weighted'), precision_score(y_test, dt_predictions, average='weighted')],
    'F1-Score': [f1_score(y_test, rf_predictions, average='weighted'), f1_score(y_test, dt_predictions, average='weighted')]
}

# Convertir el diccionario a un DataFrame de Pandas
import pandas as pd
metrics_df = pd.DataFrame(metrics)

# ---- Gráfico Comparativo de Métricas de Desempeño ----
plt.figure(figsize=(12, 6))
metrics_melted = metrics_df.melt(id_vars='Modelo', var_name='Métrica', value_name='Valor')
sns.barplot(x='Métrica', y='Valor', hue='Modelo', data=metrics_melted, palette='viridis')
plt.title('Comparación de Métricas de Desempeño: Random Forest vs Árbol de Decisión')
plt.ylabel('Puntuación')
plt.xlabel('Métrica')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.show()

# ---- Curvas ROC de Comparación de Modelos ----
# Calcular las probabilidades para ROC Curve
rf_probs = best_rf_model.predict_proba(X_test)
dt_probs = best_dt_model.predict_proba(X_test)

# Obtener las curvas ROC para ambos modelos (puedes ajustar las clases)
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_probs[:, 1], pos_label=1)
fpr_dt, tpr_dt, _ = roc_curve(y_test, dt_probs[:, 1], pos_label=1)

# Calcular el AUC (Área Bajo la Curva)
roc_auc_rf = auc(fpr_rf, tpr_rf)
roc_auc_dt = auc(fpr_dt, tpr_dt)

# Gráfico de las Curvas ROC
plt.figure(figsize=(10, 6))
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.2f})', color='blue')
plt.plot(fpr_dt, tpr_dt, label=f'Árbol de Decisión (AUC = {roc_auc_dt:.2f})', color='green')
plt.plot([0, 1], [0, 1], 'k--')  # Línea de referencia para un clasificador aleatorio
plt.title('Curvas ROC - Comparación de Modelos')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()